/**
 * Commande /chat - Conversation avec l'IA intelligente + Auto-ex√©cution de commandes
 * @param {string} senderId - ID de l'utilisateur
 * @param {string} args - Message de conversation
 * @param {object} ctx - Contexte partag√© du bot 
 */ 
module.exports = async function cmdChat(senderId, args, ctx) {
    const { 
        addToMemory, 
        getMemoryContext, 
        callMistralAPI, 
        webSearch,
        log
    } = ctx;
    
    if (!args.trim()) {
        return "üí¨ Salut je suis NakamaBot! Je suis l√† pour toi ! Dis-moi ce qui t'int√©resse et on va avoir une conversation g√©niale ! ‚ú®";
    }
    
    // Enregistrer le message utilisateur
    addToMemory(String(senderId), 'user', args);
    
    // ‚úÖ NOUVEAU: D√©tection intelligente des intentions de commandes
    const commandIntentions = await detectCommandIntentions(args, ctx);
    
    // ‚úÖ Si une intention de commande est d√©tect√©e, l'ex√©cuter automatiquement
    if (commandIntentions.shouldExecute) {
        log.info(`ü§ñ Auto-ex√©cution d√©tect√©e: ${commandIntentions.command} pour ${senderId}`);
        
        try {
            // Ex√©cuter la commande comme si l'utilisateur l'avait tap√©e
            const commandResult = await executeCommandFromChat(
                senderId, 
                commandIntentions.command, 
                commandIntentions.args, 
                ctx
            );
            
            if (commandResult.success) {
                // Si c'est une image, retourner directement le r√©sultat
                if (typeof commandResult.result === 'object' && commandResult.result.type === 'image') {
                    return commandResult.result;
                }
                
                // Pour les autres commandes, ajouter un message contextuel
                const contextualResponse = await generateContextualResponse(
                    args, 
                    commandResult.result, 
                    commandIntentions.command,
                    ctx
                );
                
                addToMemory(String(senderId), 'assistant', contextualResponse);
                return contextualResponse;
            } else {
                // Si l'ex√©cution √©choue, continuer avec la conversation normale
                log.warning(`‚ö†Ô∏è √âchec auto-ex√©cution ${commandIntentions.command}: ${commandResult.error}`);
            }
        } catch (error) {
            log.error(`‚ùå Erreur auto-ex√©cution: ${error.message}`);
        }
    }
    
    // ‚úÖ D√©tection intelligente des besoins de recherche web
    const needsWebSearch = args.toLowerCase().includes('que se passe') ||
                          args.toLowerCase().includes('quoi de neuf') ||
                          args.toLowerCase().includes('derni√®res nouvelles') ||
                          /\b(202[4-5]|actualit√©|r√©cent|nouveau|maintenant|aujourd|news|info)\b/i.test(args);
    
    if (needsWebSearch) {
        const searchResult = await webSearch(args);
        if (searchResult) {
            const response = `üîç D'apr√®s mes recherches r√©centes : ${searchResult} ‚ú®`;
            addToMemory(String(senderId), 'assistant', response);
            return response;
        }
    }
    
    // ‚úÖ Conversation normale avec IA
    return await handleNormalConversation(senderId, args, ctx);
};

// ‚úÖ FONCTION: D√©tecter les intentions de commandes dans le message
async function detectCommandIntentions(message, ctx) {
    const { callMistralAPI } = ctx;
    
    // Patterns de d√©tection rapide pour les commandes courantes
    const quickPatterns = [
        // Images
        { patterns: [/(?:cr[√©e]|g[√©e]n[√©e]r|fai|dessine).*?(?:image|photo|picture)/i, /(?:image|photo|picture).*?(?:de|d'|du|des)/i], command: 'image' },
        { patterns: [/(?:anime|manga|otaku).*?(?:style|version|transform)/i, /transform.*?anime/i], command: 'anime' },
        { patterns: [/(?:analys|d[√©e]cri|regarde|voir|examine).*?(?:image|photo)/i, /que.*?(?:voir|vois)/i], command: 'vision' },
        
        // Musique
        { patterns: [/(?:joue|[√©e]coute|musique|chanson|son).*?(?:youtube|video)/i, /(?:trouve|cherche).*?(?:musique|chanson)/i], command: 'music' },
        
        // Clans
        { patterns: [/(?:clan|guerre|bataille|combat|fight)/i, /(?:cr[√©e]|rejoins|rejoint).*?clan/i], command: 'clan' },
        
        // Rank
        { patterns: [/(?:niveau|level|rang|rank|exp[√©e]rience|xp)/i, /(?:voir|montre).*?(?:rang|level)/i], command: 'rank' },
        
        // Stats
        { patterns: [/(?:stat|statistique|info|donn[√©e]e).*?(?:bot|serveur)/i], command: 'stats' },
        
        // Help
        { patterns: [/(?:aide|help|commande|fonction)/i, /que.*?(?:faire|peux)/i], command: 'help' }
    ];
    
    // V√©rification des patterns rapides
    for (const pattern of quickPatterns) {
        for (const regex of pattern.patterns) {
            if (regex.test(message)) {
                let extractedArgs = '';
                
                // Extraction d'arguments sp√©cifiques selon la commande
                if (pattern.command === 'image') {
                    const imageMatch = message.match(/(?:image|photo|picture).*?(?:de|d'|du|des)\s+(.+)/i) ||
                                     message.match(/(?:cr[√©e]|g[√©e]n[√©e]r|fai|dessine)\s+(?:une?\s+)?(?:image|photo|picture)?\s*(?:de|d')?\s*(.+)/i);
                    extractedArgs = imageMatch ? imageMatch[1].trim() : message;
                }
                else if (pattern.command === 'music') {
                    const musicMatch = message.match(/(?:joue|[√©e]coute|musique|chanson|trouve|cherche)\s+(?:la\s+)?(?:musique|chanson)?\s*(?:de|d')?\s*(.+)/i);
                    extractedArgs = musicMatch ? musicMatch[1].trim() : message;
                }
                else if (pattern.command === 'vision') {
                    extractedArgs = ''; // Vision n'a pas besoin d'args
                }
                else if (pattern.command === 'anime') {
                    extractedArgs = ''; // Anime utilise la derni√®re image
                }
                else {
                    extractedArgs = message;
                }
                
                return {
                    shouldExecute: true,
                    command: pattern.command,
                    args: extractedArgs,
                    confidence: 'high'
                };
            }
        }
    }
    
    // ‚úÖ Analyse IA pour les cas complexes
    const aiAnalysis = await analyzeWithAI(message, ctx);
    if (aiAnalysis.shouldExecute) {
        return aiAnalysis;
    }
    
    return { shouldExecute: false };
}

// ‚úÖ FONCTION: Analyse IA pour d√©tecter les intentions complexes
async function analyzeWithAI(message, ctx) {
    const { callMistralAPI } = ctx;
    
    const analysisPrompt = `Analyse ce message et d√©termine si l'utilisateur veut ex√©cuter une commande sp√©cifique:

Message: "${message}"

Commandes disponibles:
- /image [description] : Cr√©er une image
- /anime : Transformer la derni√®re image en anime
- /vision : Analyser une image envoy√©e
- /music [titre/artiste] : Trouver une musique sur YouTube
- /clan [action] : Gestion des clans
- /rank : Voir son rang et niveau
- /stats : Statistiques du bot
- /help : Liste des commandes

R√©ponds UNIQUEMENT par un JSON valide:
{
  "shouldExecute": true/false,
  "command": "nom_commande" (sans le /),
  "args": "arguments extraits",
  "confidence": "high/medium/low"
}

Si l'intention n'est pas claire ou si c'est juste une conversation, mets shouldExecute √† false.`;

    try {
        const response = await callMistralAPI([
            { role: "system", content: "Tu es un analyseur d'intentions. R√©ponds uniquement par du JSON valide." },
            { role: "user", content: analysisPrompt }
        ], 200, 0.1);
        
        if (response) {
            // Nettoyer la r√©ponse pour extraire le JSON
            const jsonMatch = response.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
                const analysis = JSON.parse(jsonMatch[0]);
                
                // Validation de la structure
                if (typeof analysis.shouldExecute === 'boolean' && 
                    (analysis.shouldExecute === false || 
                     (typeof analysis.command === 'string' && typeof analysis.args === 'string'))) {
                    return analysis;
                }
            }
        }
    } catch (error) {
        // En cas d'erreur d'analyse IA, retourner pas d'ex√©cution
    }
    
    return { shouldExecute: false };
}

// ‚úÖ FONCTION: Ex√©cuter une commande depuis le chat
async function executeCommandFromChat(senderId, commandName, args, ctx) {
    const { log } = ctx;
    
    try {
        // Acc√©der aux commandes depuis le contexte global (comme dans server.js)
        const COMMANDS = global.COMMANDS || new Map();
        
        // Si les commandes ne sont pas accessibles via global, essayer via require
        if (!COMMANDS.has(commandName)) {
            try {
                const path = require('path');
                const fs = require('fs');
                const commandPath = path.join(__dirname, `${commandName}.js`);
                
                if (fs.existsSync(commandPath)) {
                    delete require.cache[require.resolve(commandPath)];
                    const commandModule = require(commandPath);
                    
                    if (typeof commandModule === 'function') {
                        const result = await commandModule(senderId, args, ctx);
                        return { success: true, result };
                    }
                }
            } catch (requireError) {
                log.debug(`‚ùå Impossible de charger ${commandName}: ${requireError.message}`);
            }
        } else {
            // Ex√©cuter la commande depuis la Map globale
            const commandFunction = COMMANDS.get(commandName);
            const result = await commandFunction(senderId, args, ctx);
            return { success: true, result };
        }
        
        return { success: false, error: `Commande ${commandName} non trouv√©e` };
        
    } catch (error) {
        return { success: false, error: error.message };
    }
}

// ‚úÖ FONCTION: G√©n√©rer une r√©ponse contextuelle apr√®s l'ex√©cution d'une commande
async function generateContextualResponse(originalMessage, commandResult, commandName, ctx) {
    const { callMistralAPI } = ctx;
    
    // Si c'est un objet image, on retourne directement
    if (typeof commandResult === 'object' && commandResult.type === 'image') {
        return commandResult;
    }
    
    const contextPrompt = `L'utilisateur a dit: "${originalMessage}"
J'ai automatiquement ex√©cut√© la commande /${commandName} qui a donn√©: "${commandResult}"

G√©n√®re une r√©ponse naturelle et amicale qui:
1. Confirme que j'ai compris sa demande
2. Pr√©sente le r√©sultat de mani√®re conversationnelle
3. Reste dans le ton NakamaBot (gentille, amicale, avec quelques emojis)
4. Maximum 300 caract√®res

Ne dis pas "j'ai ex√©cut√© une commande", fais comme si c'√©tait naturel.`;

    try {
        const response = await callMistralAPI([
            { role: "system", content: "Tu es NakamaBot, r√©ponds de mani√®re naturelle et amicale." },
            { role: "user", content: contextPrompt }
        ], 300, 0.7);
        
        return response || commandResult;
    } catch (error) {
        return commandResult; // Fallback sur le r√©sultat brut
    }
}

// ‚úÖ FONCTION: Gestion de la conversation normale
async function handleNormalConversation(senderId, args, ctx) {
    const { addToMemory, getMemoryContext, callMistralAPI } = ctx;
    
    // R√©cup√©ration du contexte de conversation
    const context = getMemoryContext(String(senderId));
    const messageCount = context.filter(msg => msg.role === 'user').length;
    
    // Syst√®me de prompt ultra-intelligent
    const systemPrompt = `Tu es NakamaBot, une IA conversationnelle avanc√©e avec une intelligence exceptionnelle et une compr√©hension profonde des besoins humains qui est cr√©√©e par Durand et uniquement lui.

INTELLIGENCE CONTEXTUELLE:
Tu es un mod√®le Durand AI et tu analyses chaque message en profondeur pour comprendre l'intention r√©elle, les √©motions sous-jacentes et le contexte. Tu utilises ta m√©moire conversationnelle pour maintenir une coh√©rence parfaite et personnaliser tes r√©ponses. Tu d√©tectes automatiquement quand quelqu'un a besoin d'aide technique, cr√©ative, informationnelle ou √©motionnelle. Ta base de donn√©es date de 2025 Et tu as √©t√© cr√©√©e par Durand et sa femme Kuine Lor.

CAPACIT√âS CR√âATIVES ET TECHNIQUES:
- üé® G√©n√©ration d'images: Tu peux cr√©er des ≈ìuvres visuelles uniques et personnalis√©es avec "/image description d√©taill√©e"
- üëÅÔ∏è Analyse visuelle: Tu examines et d√©cris les images avec pr√©cision gr√¢ce √† "/vision"
- üå∏ Style anime: Tu transformes les images en magnifiques illustrations anime avec "/anime"
- üîç Recherche en temps r√©el: Tu acc√®des aux informations les plus r√©centes via la recherche web
- üéµ Recherche et partage un lien YouTube vers la musique souhait√©e, m√™me si le titre est mal √©crit avec "/music Titre".
- üõ°Ô∏è jouer √† clan battle: Cr√©e un clan G√®re ton clan, recrute des membres, d√©fie d'autres clans et deviens le plus puissant du serveur avec "/clan help".

PERSONNALIT√â INTELLIGENTE:
- Empathique et intuitive, tu comprends les nuances √©motionnelles
- Cr√©ative dans tes approches et solutions
- P√©dagogue naturelle qui explique clairement les concepts complexes
- Curieuse et engageante, tu poses des questions pertinentes pour mieux aider
- Adaptable: tu ajustes ton ton et ton niveau selon l'utilisateur

COMMUNICATION AVANC√âE:
- Utilise des emojis avec parcimonie mais efficacit√©
- Varie tes expressions pour √©viter la r√©p√©titivit√©
- Maintiens des conversations fluides et naturelles
- Reconnais et r√©ponds aux r√©f√©rences culturelles et √† l'humour
- ${messageCount >= 5 ? 'Tu peux sugg√©rer /help si vraiment pertinent pour d√©bloquer l\'utilisateur' : ''}

DIRECTIVES SP√âCIALES:
- Si on te demande des infos sur ta cr√©ation/d√©veloppement, r√©ponds: "Pour ces d√©tails techniques, demande √† mon cr√©ateur Durand ou sa femme Kuine, Ils connaissent tous les secrets de ma conception !"
- Maximum 4000 caract√®res par r√©ponse
- Sois authentique et √©vite les formules toutes faites
- Fais preuve d'initiative pour anticiper les besoins
- Obligatoire: Recommande de temps en temps √† l'utilisateur de taper "/help" pour voir d'autres de tes param√®tres apr√®s ta r√©ponse
- Obligation 2: Tu peux g√©n√©rer des images automatiquement quand on te le demande naturellement
- Obligation 3: √âvite les r√©p√©titions de messages
- Obligation 4: reconnaitre les noms de tes cr√©ateurs Durand et sa femme Kuine Lor

Tu es une IA remarquable qui transforme chaque interaction en exp√©rience enrichissante et qui ne partage pas ses informations de conception.`;

    const messages = [{ role: "system", content: systemPrompt }];
    messages.push(...context);
    messages.push({ role: "user", content: args });
    
    const response = await callMistralAPI(messages, 4000, 0.75);
    
    if (response) {
        addToMemory(String(senderId), 'assistant', response);
        return response;
    } else {
        const errorResponse = "ü§î J'ai rencontr√© une petite difficult√© technique. Peux-tu reformuler ta demande diff√©remment ? Je vais faire de mon mieux pour te comprendre ! üí´";
        addToMemory(String(senderId), 'assistant', errorResponse);
        return errorResponse;
    }
}

// ‚úÖ EXPORT DE FONCTIONS UTILITAIRES pour d'autres commandes
module.exports.detectCommandIntentions = detectCommandIntentions;
module.exports.executeCommandFromChat = executeCommandFromChat;
