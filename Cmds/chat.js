/**
 * NakamaBot - Commande /chat avec IA pure pour d√©tection intelligente
 * @param {string} senderId - ID de l'utilisateur
 * @param {string} args - Message de conversation
 * @param {object} ctx - Contexte partag√© du bot 
 */

const { GoogleGenerativeAI } = require("@google/generative-ai");
const axios = require("axios");

// Configuration APIs - Support de cl√©s multiples pour Gemini
const GEMINI_API_KEYS = process.env.GEMINI_API_KEY ? process.env.GEMINI_API_KEY.split(',').map(key => key.trim()) : [];
const GOOGLE_SEARCH_API_KEY = process.env.GOOGLE_SEARCH_API_KEY;
const GOOGLE_SEARCH_ENGINE_ID = process.env.GOOGLE_SEARCH_ENGINE_ID;
const SERPAPI_KEY = process.env.SERPAPI_KEY;

// Gestion rotation des cl√©s Gemini
let currentGeminiKeyIndex = 0;

function getNextGeminiAPI() {
    if (GEMINI_API_KEYS.length === 0) {
        throw new Error('Aucune cl√© Gemini configur√©e');
    }
    
    const apiKey = GEMINI_API_KEYS[currentGeminiKeyIndex];
    currentGeminiKeyIndex = (currentGeminiKeyIndex + 1) % GEMINI_API_KEYS.length;
    
    return new GoogleGenerativeAI(apiKey);
}

module.exports = async function cmdChat(senderId, args, ctx) {
    const { addToMemory, getMemoryContext, callMistralAPI, log } = ctx;
    
    if (!args.trim()) {
        return "üí¨ Salut je suis NakamaBot! Je suis l√† pour toi ! Dis-moi ce qui t'int√©resse et on va avoir une conversation g√©niale ! ‚ú®";
    }
    
    // ‚úÖ D√©tection contact admin (conserv√©e car sp√©cifique)
    const contactIntention = await detectContactAdminIntention(args, ctx);
    if (contactIntention.shouldContact) {
        log.info(`üìû Intention contact admin d√©tect√©e pour ${senderId}: ${contactIntention.reason}`);
        const contactSuggestion = generateContactSuggestion(contactIntention.reason, contactIntention.extractedMessage);
        addToMemory(String(senderId), 'user', args);
        addToMemory(String(senderId), 'assistant', contactSuggestion);
        return contactSuggestion;
    }
    
    // ü§ñ ANALYSE IA COMPL√àTE DU MESSAGE
    const aiAnalysis = await performCompleteAIAnalysis(args, senderId, ctx);
    
    // üéØ Ex√©cution de commande d√©tect√©e
    if (aiAnalysis.commandDetected && aiAnalysis.shouldExecuteCommand) {
        log.info(`üéØ Commande IA d√©tect√©e: ${aiAnalysis.detectedCommand} (confiance: ${aiAnalysis.commandConfidence}) pour ${senderId}`);
        
        try {
            const commandResult = await executeCommandFromChat(senderId, aiAnalysis.detectedCommand, aiAnalysis.extractedArgs, ctx);
            
            if (commandResult.success) {
                // Gestion sp√©ciale pour les images
                if (typeof commandResult.result === 'object' && commandResult.result.type === 'image') {
                    addToMemory(String(senderId), 'user', args);
                    return commandResult.result;
                }
                
                // R√©ponse contextuelle naturelle
                const contextualResponse = await generateContextualResponse(args, commandResult.result, aiAnalysis.detectedCommand, ctx);
                addToMemory(String(senderId), 'user', args);
                addToMemory(String(senderId), 'assistant', contextualResponse);
                return contextualResponse;
            } else {
                log.warning(`‚ö†Ô∏è √âchec ex√©cution commande ${aiAnalysis.detectedCommand}: ${commandResult.error}`);
            }
        } catch (error) {
            log.error(`‚ùå Erreur ex√©cution commande intelligente: ${error.message}`);
        }
    }
    
    // üîç Recherche externe si n√©cessaire
    if (aiAnalysis.needsExternalSearch && aiAnalysis.shouldPerformSearch) {
        log.info(`üîç Recherche externe IA requise pour ${senderId}: ${aiAnalysis.searchReason}`);
        
        try {
            const searchResults = await performIntelligentSearch(aiAnalysis.optimizedSearchQuery, ctx);
            
            if (searchResults && searchResults.length > 0) {
                const naturalResponse = await generateNaturalResponse(args, searchResults, ctx);
                if (naturalResponse) {
                    addToMemory(String(senderId), 'user', args);
                    addToMemory(String(senderId), 'assistant', naturalResponse);
                    return naturalResponse;
                }
            } else {
                log.warning(`‚ö†Ô∏è Aucun r√©sultat de recherche pour: ${aiAnalysis.optimizedSearchQuery}`);
            }
        } catch (searchError) {
            log.error(`‚ùå Erreur recherche intelligente: ${searchError.message}`);
        }
    }
    
    // üí¨ Conversation classique avec Gemini (Mistral en fallback)
    return await handleConversationWithFallback(senderId, args, ctx);
};

// üß† ANALYSE IA COMPL√àTE - Tout en une seule passe
async function performCompleteAIAnalysis(userMessage, senderId, ctx) {
    const { log } = ctx;
    
    try {
        const genAI = getNextGeminiAPI();
        const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
        
        const now = new Date();
        const dateTime = now.toLocaleString('fr-FR', { 
            weekday: 'long', 
            year: 'numeric', 
            month: 'long', 
            day: 'numeric', 
            hour: '2-digit', 
            minute: '2-digit',
            timeZone: 'Europe/Paris'
        });
        
        const analysisPrompt = `Tu es le syst√®me d'analyse intelligent de NakamaBot. Analyse ce message utilisateur pour d√©terminer les actions n√©cessaires.

CONTEXTE TEMPOREL: ${dateTime}

COMMANDES DISPONIBLES:
- help: Afficher l'aide et toutes les commandes
- image: Cr√©er des images uniques avec l'IA
- vision: Analyser des images avec pr√©cision  
- anime: Transformer images en style anime/manga
- music: Trouver musique sur YouTube
- clan: Syst√®me de clans et batailles
- rank: Voir niveau et progression
- contact: Contacter les administrateurs
- weather: Informations m√©t√©o actuelles

MESSAGE UTILISATEUR: "${userMessage}"

ANALYSE REQUISE:

1. D√âTECTION DE COMMANDE:
   - L'utilisateur veut-il utiliser une fonctionnalit√© sp√©cifique ?
   - Quelle commande correspond √† son intention ?
   - Quels sont les arguments √† extraire ?

2. N√âCESSIT√â DE RECHERCHE EXTERNE:
   - Le message n√©cessite-t-il des informations r√©centes/actuelles ?
   - S'agit-il de donn√©es factuelles sp√©cifiques non connues ?
   - Quelle requ√™te de recherche serait optimale ?

3. TYPE DE R√âPONSE ATTENDUE:
   - Conversation g√©n√©rale
   - Ex√©cution de commande
   - Recherche d'informations
   - Aide/support

R√©ponds UNIQUEMENT avec ce JSON structur√©:
{
  "analysisType": "command|search|conversation|help",
  "commandDetected": true/false,
  "detectedCommand": "nom_commande_ou_null",
  "commandConfidence": 0.0-1.0,
  "shouldExecuteCommand": true/false,
  "extractedArgs": "arguments_extraits_ou_message_complet",
  "needsExternalSearch": true/false,
  "shouldPerformSearch": true/false,
  "searchConfidence": 0.0-1.0,
  "searchReason": "pourquoi_recherche_necessaire",
  "optimizedSearchQuery": "requete_optimisee",
  "conversationType": "general|technical|creative|support",
  "userIntent": "description_intention_utilisateur",
  "reasoning": "explication_courte_du_raisonnement"
}`;

        const result = await model.generateContent(analysisPrompt);
        const response = result.response.text();
        
        // Extraire le JSON de la r√©ponse
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
            const analysis = JSON.parse(jsonMatch[0]);
            
            log.info(`üß† Analyse IA compl√®te: ${analysis.analysisType} | Commande: ${analysis.detectedCommand || 'aucune'} | Recherche: ${analysis.needsExternalSearch ? 'oui' : 'non'}`);
            
            return {
                ...analysis,
                // Valeurs par d√©faut pour √©viter les erreurs
                commandDetected: analysis.commandDetected || false,
                shouldExecuteCommand: analysis.shouldExecuteCommand || false,
                needsExternalSearch: analysis.needsExternalSearch || false,
                shouldPerformSearch: analysis.shouldPerformSearch || false,
                commandConfidence: analysis.commandConfidence || 0,
                searchConfidence: analysis.searchConfidence || 0
            };
        }
        
        throw new Error('Format JSON invalide');
        
    } catch (error) {
        log.warning(`‚ö†Ô∏è Erreur analyse IA compl√®te: ${error.message}`);
        
        // Fallback minimal
        return {
            analysisType: 'conversation',
            commandDetected: false,
            shouldExecuteCommand: false,
            needsExternalSearch: false,
            shouldPerformSearch: false,
            conversationType: 'general',
            userIntent: 'conversation_generale',
            reasoning: 'fallback_error'
        };
    }
}

// üîç RECHERCHE INTELLIGENTE - Inchang√©e mais simplifi√©e
async function performIntelligentSearch(query, ctx) {
    const { log } = ctx;
    
    try {
        // Priorit√© 1: Google Custom Search API
        if (GOOGLE_SEARCH_API_KEY && GOOGLE_SEARCH_ENGINE_ID) {
            return await googleCustomSearch(query, log);
        }
        
        // Priorit√© 2: SerpAPI (fallback)
        if (SERPAPI_KEY) {
            return await serpApiSearch(query, log);
        }
        
        log.warning('‚ö†Ô∏è Aucune API de recherche configur√©e');
        return [];
        
    } catch (error) {
        log.error(`‚ùå Erreur recherche: ${error.message}`);
        return [];
    }
}

// Google Custom Search API
async function googleCustomSearch(query, log) {
    const url = `https://www.googleapis.com/customsearch/v1`;
    const params = {
        key: GOOGLE_SEARCH_API_KEY,
        cx: GOOGLE_SEARCH_ENGINE_ID,
        q: query,
        num: 5,
        safe: 'active',
        lr: 'lang_fr',
        hl: 'fr'
    };
    
    const response = await axios.get(url, { params, timeout: 10000 });
    
    if (response.data.items) {
        return response.data.items.map(item => ({
            title: item.title,
            link: item.link,
            description: item.snippet,
            source: 'google'
        }));
    }
    
    return [];
}

// SerpAPI (alternative)
async function serpApiSearch(query, log) {
    const url = `https://serpapi.com/search`;
    const params = {
        api_key: SERPAPI_KEY,
        engine: 'google',
        q: query,
        num: 5,
        hl: 'fr',
        gl: 'fr'
    };
    
    const response = await axios.get(url, { params, timeout: 10000 });
    
    if (response.data.organic_results) {
        return response.data.organic_results.map(item => ({
            title: item.title,
            link: item.link,
            description: item.snippet,
            source: 'serpapi'
        }));
    }
    
    return [];
}

// üé≠ G√âN√âRATION DE R√âPONSE NATURELLE (avec recherche)
async function generateNaturalResponse(originalQuery, searchResults, ctx) {
    const { log, callMistralAPI } = ctx;
    
    const now = new Date();
    const dateTime = now.toLocaleString('fr-FR', { 
        weekday: 'long', 
        year: 'numeric', 
        month: 'long', 
        day: 'numeric', 
        hour: '2-digit', 
        minute: '2-digit',
        timeZone: 'Europe/Paris'
    });
    
    try {
        const genAI = getNextGeminiAPI();
        const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
        
        const resultsText = searchResults.map((result, index) => 
            `${result.title}: ${result.description}`
        ).join('\n');
        
        const naturalPrompt = `Tu es NakamaBot, une IA conversationnelle empathique et cr√©ative.

CONTEXTE TEMPOREL: ${dateTime}

L'utilisateur te demande: "${originalQuery}"

Informations actuelles pertinentes:
${resultsText}

INSTRUCTIONS:
- R√©ponds comme si tu connaissais naturellement ces informations
- Ton conversationnel et amical avec quelques emojis
- Maximum 2500 caract√®res
- Ne mentionne JAMAIS que tu as fait une recherche
- Ne dis jamais "d'apr√®s mes recherches" ou "selon les sources"  
- R√©ponds comme dans une conversation normale entre amis
- Si l'information n'est pas compl√®te, reste naturel et honn√™te

R√âPONSE NATURELLE:`;

        const result = await model.generateContent(naturalPrompt);
        const response = result.response.text();
        
        if (response && response.trim()) {
            log.info(`üé≠ R√©ponse naturelle Gemini g√©n√©r√©e`);
            return response;
        }
        
        throw new Error('R√©ponse Gemini vide');
        
    } catch (geminiError) {
        log.warning(`‚ö†Ô∏è Erreur r√©ponse naturelle Gemini: ${geminiError.message}`);
        
        try {
            // Fallback Mistral
            const messages = [{
                role: "system",
                content: "Tu es NakamaBot. R√©ponds naturellement comme dans une conversation normale. Ne mentionne jamais de recherches ou sources."
            }, {
                role: "user", 
                content: `Question: "${originalQuery}"\n\nInformations utiles:\n${searchResults.map(r => `${r.title}: ${r.description}`).join('\n')}\n\nR√©ponds naturellement comme si tu connaissais d√©j√† ces infos (max 2500 chars):`
            }];
            
            const mistralResponse = await callMistralAPI(messages, 2500, 0.7);
            
            if (mistralResponse) {
                log.info(`üîÑ R√©ponse naturelle Mistral g√©n√©r√©e`);
                return mistralResponse;
            }
            
            throw new Error('Mistral aussi en √©chec');
            
        } catch (mistralError) {
            log.error(`‚ùå Erreur r√©ponse naturelle totale: ${mistralError.message}`);
            
            // Derniers recours
            const topResult = searchResults[0];
            if (topResult) {
                return `D'apr√®s ce que je sais, ${topResult.description} üí° ${searchResults.length > 1 ? 'Il y a aussi d\'autres aspects int√©ressants sur le sujet !' : 'J\'esp√®re que √ßa r√©pond √† ta question !'}`;
            }
            
            return null;
        }
    }
}

// üí¨ CONVERSATION NORMALE (avec rotation Gemini)
async function handleConversationWithFallback(senderId, args, ctx) {
    const { addToMemory, getMemoryContext, callMistralAPI, log } = ctx;
    
    // Contexte optimis√© (8 derniers messages)
    const context = getMemoryContext(String(senderId)).slice(-8);
    const messageCount = context.filter(msg => msg.role === 'user').length;
    
    const now = new Date();
    const dateTime = now.toLocaleString('fr-FR', { 
        weekday: 'long', 
        year: 'numeric', 
        month: 'long', 
        day: 'numeric', 
        hour: '2-digit', 
        minute: '2-digit',
        timeZone: 'Europe/Paris'
    });
    
    // Construction historique conversation
    let conversationHistory = "";
    if (context.length > 0) {
        conversationHistory = context.map(msg => 
            `${msg.role === 'user' ? 'Utilisateur' : 'Assistant'}: ${msg.content}`
        ).join('\n') + '\n';
    }
    
    // Prompt syst√®me optimis√©
    const systemPrompt = `Tu es NakamaBot, une IA conversationnelle avanc√©e cr√©√©e par Durand et C√©cile.

CONTEXTE TEMPOREL: ${dateTime}

INTELLIGENCE & PERSONNALIT√â:
- Empathique, cr√©ative et intuitive
- Comprends les √©motions et intentions sous-jacentes  
- P√©dagogue naturelle qui explique clairement
- Adaptable selon l'utilisateur et le contexte

CAPACIT√âS PRINCIPALES:
üé® Cr√©ation d'images intelligente (dis "dessine-moi..." ou "cr√©e une image de...")
üëÅÔ∏è Analyse d'images avanc√©e (dis "regarde cette image" ou "que vois-tu ?")
üå∏ Transformation anime/manga (dis "transforme en anime" ou "style manga")
üéµ Recherche musicale YouTube (dis "joue..." ou "trouve la musique...")
üõ°Ô∏è Syst√®me de clans et batailles (dis "clan" ou "bataille")
üìä Progression et niveau (dis "mon niveau" ou "mes stats")
üìû Contact admin (dis "contacter admin" ou utilise /contact)
üîç Recherche intelligente automatique pour infos r√©centes
üÜò Guide complet (dis "aide" ou "que peux-tu faire ?")

DIRECTIVES:
- Parle en fonction de la langue utilis√©e par l'utilisateur
- Maximum 3000 caract√®res par r√©ponse
- Utilise quelques emojis avec parcimonie
- √âvite les r√©p√©titions et formules toutes faites
- ${messageCount >= 5 ? 'Sugg√®re /help si pertinent' : ''}
- Pour questions techniques: "Demande √† Durand ou C√©cile, ils connaissent tous mes secrets !"
- Recommande /contact pour probl√®mes techniques graves

${conversationHistory ? `Historique:\n${conversationHistory}` : ''}

Utilisateur: ${args}`;

    try {
        // Essayer avec Gemini (rotation automatique)
        const genAI = getNextGeminiAPI();
        const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
        const result = await model.generateContent(systemPrompt);
        const geminiResponse = result.response.text();
        
        if (geminiResponse && geminiResponse.trim()) {
            addToMemory(String(senderId), 'user', args);
            addToMemory(String(senderId), 'assistant', geminiResponse);
            log.info(`üíé Gemini r√©ponse (cl√© ${currentGeminiKeyIndex}) pour ${senderId}`);
            return geminiResponse;
        }
        
        throw new Error('R√©ponse Gemini vide');
        
    } catch (geminiError) {
        log.warning(`‚ö†Ô∏è Gemini √©chec (cl√© ${currentGeminiKeyIndex}) pour ${senderId}: ${geminiError.message}`);
        
        try {
            // Fallback Mistral
            const messages = [{ role: "system", content: systemPrompt }];
            messages.push(...context);
            messages.push({ role: "user", content: args });
            
            const mistralResponse = await callMistralAPI(messages, 2000, 0.75);
            
            if (mistralResponse) {
                addToMemory(String(senderId), 'user', args);
                addToMemory(String(senderId), 'assistant', mistralResponse);
                log.info(`üîÑ Mistral fallback pour ${senderId}`);
                return mistralResponse;
            }
            
            throw new Error('Mistral aussi en √©chec');
            
        } catch (mistralError) {
            log.error(`‚ùå Erreur totale conversation ${senderId}: Gemini + Mistral`);
            
            const errorResponse = "ü§î J'ai rencontr√© une petite difficult√© technique. Peux-tu reformuler ta demande diff√©remment ? üí´";
            addToMemory(String(senderId), 'assistant', errorResponse);
            return errorResponse;
        }
    }
}

// ‚úÖ FONCTIONS UTILITAIRES (conserv√©es et simplifi√©es)

async function detectContactAdminIntention(message, ctx) {
    const { log } = ctx;
    
    try {
        const genAI = getNextGeminiAPI();
        const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
        
        const contactPrompt = `Analyse ce message pour d√©terminer si l'utilisateur veut contacter les administrateurs.

MESSAGE: "${message}"

CRIT√àRES CONTACT ADMIN:
‚úÖ Demande explicite de contact admin/cr√©ateurs
‚úÖ Probl√®me technique grave/urgent  
‚úÖ Signalement important
‚úÖ Suggestion d'am√©lioration
‚úÖ R√©clamation/plainte

‚ùå Questions g√©n√©rales sur le bot
‚ùå Conversation normale
‚ùå Questions sur cr√©ation (g√©r√© par IA)

R√©ponds UNIQUEMENT:
{
  "shouldContact": true/false,
  "reason": "contact_direct|probleme_technique|signalement|suggestion|plainte|aucun",
  "extractedMessage": "message_original"
}`;

        const result = await model.generateContent(contactPrompt);
        const response = result.response.text();
        
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
            const analysis = JSON.parse(jsonMatch[0]);
            return {
                shouldContact: analysis.shouldContact || false,
                reason: analysis.reason || 'aucun',
                extractedMessage: analysis.extractedMessage || message
            };
        }
        
    } catch (error) {
        log.warning(`‚ö†Ô∏è Erreur d√©tection contact admin: ${error.message}`);
    }
    
    return { shouldContact: false };
}

function generateContactSuggestion(reason, extractedMessage) {
    const reasonMessages = {
        'contact_direct': { title: "üíå **Contact Admin**", message: "Je vois que tu veux contacter les administrateurs !" },
        'probleme_technique': { title: "üîß **Probl√®me Technique**", message: "Probl√®me technique d√©tect√© !" },
        'signalement': { title: "üö® **Signalement**", message: "Tu veux signaler quelque chose d'important !" },
        'suggestion': { title: "üí° **Suggestion**", message: "Tu as une suggestion d'am√©lioration !" },
        'plainte': { title: "üìù **R√©clamation**", message: "Tu as une r√©clamation √† formuler !" }
    };
    
    const reasonData = reasonMessages[reason] || {
        title: "üìû **Contact Admin**",
        message: "Il semble que tu aies besoin de contacter les administrateurs !"
    };
    
    const preview = extractedMessage.length > 60 ? extractedMessage.substring(0, 60) + "..." : extractedMessage;
    
    return `${reasonData.title}\n\n${reasonData.message}\n\nüí° **Solution :** Utilise \`/contact [ton message]\` pour les contacter directement.\n\nüìù **Ton message :** "${preview}"\n\n‚ö° **Limite :** 2 messages par jour\nüì® Tu recevras une r√©ponse personnalis√©e !\n\nüíï En attendant, je peux t'aider avec d'autres choses ! Tape /help pour voir mes fonctionnalit√©s !`;
}

async function executeCommandFromChat(senderId, commandName, args, ctx) {
    try {
        const COMMANDS = global.COMMANDS || new Map();
        
        if (!COMMANDS.has(commandName)) {
            const path = require('path');
            const fs = require('fs');
            const commandPath = path.join(__dirname, `${commandName}.js`);
            
            if (fs.existsSync(commandPath)) {
                delete require.cache[require.resolve(commandPath)];
                const commandModule = require(commandPath);
                
                if (typeof commandModule === 'function') {
                    const result = await commandModule(senderId, args, ctx);
                    return { success: true, result };
                }
            }
        } else {
            const commandFunction = COMMANDS.get(commandName);
            const result = await commandFunction(senderId, args, ctx);
            return { success: true, result };
        }
        
        return { success: false, error: `Commande ${commandName} non trouv√©e` };
        
    } catch (error) {
        return { success: false, error: error.message };
    }
}

async function generateContextualResponse(originalMessage, commandResult, commandName, ctx) {
    if (typeof commandResult === 'object' && commandResult.type === 'image') {
        return commandResult;
    }
    
    try {
        const genAI = getNextGeminiAPI();
        const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
        
        const contextPrompt = `L'utilisateur a dit: "${originalMessage}"
J'ai ex√©cut√© /${commandName} avec r√©sultat: "${commandResult}"

G√©n√®re une r√©ponse naturelle et amicale (max 400 chars) qui pr√©sente le r√©sultat de mani√®re conversationnelle.`;

        const result = await model.generateContent(contextPrompt);
        return result.response.text() || commandResult;
        
    } catch (error) {
        const { callMistralAPI } = ctx;
        try {
            const response = await callMistralAPI([
                { role: "system", content: "R√©ponds naturellement et amicalement." },
                { role: "user", content: `Utilisateur: "${originalMessage}"\nR√©sultat: "${commandResult}"\nPr√©sente ce r√©sultat naturellement (max 200 chars)` }
            ], 200, 0.7);
            
            return response || commandResult;
        } catch (mistralError) {
            return commandResult;
        }
    }
}
