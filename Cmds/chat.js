/**
 * NakamaBot - Commande /chat avec recherche intelligente intÃ©grÃ©e et rotation des clÃ©s Gemini
 * + Support Markdown vers Unicode stylisÃ© pour Facebook Messenger
 * + SystÃ¨me de troncature synchronisÃ© avec le serveur principal
 * @param {string} senderId - ID de l'utilisateur
 * @param {string} args - Message de conversation
 * @param {object} ctx - Contexte partagÃ© du bot 
 */

const { GoogleGenerativeAI } = require("@google/generative-ai");
const axios = require("axios");

// Configuration APIs avec rotation des clÃ©s Gemini
const GEMINI_API_KEYS = process.env.GEMINI_API_KEY ? process.env.GEMINI_API_KEY.split(',').map(key => key.trim()) : [];
const GOOGLE_SEARCH_API_KEY = process.env.GOOGLE_SEARCH_API_KEY;
const GOOGLE_SEARCH_ENGINE_ID = process.env.GOOGLE_SEARCH_ENGINE_ID;

// Fallback: SerpAPI si Google Custom Search n'est pas disponible
const SERPAPI_KEY = process.env.SERPAPI_KEY;

// Ã‰tat global pour la rotation des clÃ©s
let currentGeminiKeyIndex = 0;
const failedKeys = new Set();

// ğŸ›¡ï¸ PROTECTION ANTI-DOUBLONS RENFORCÃ‰E: Map pour tracker les demandes en cours
const activeRequests = new Map();
const recentMessages = new Map(); // Cache des messages rÃ©cents pour Ã©viter les doublons

// ğŸ¨ FONCTIONS DE PARSING MARKDOWN â†’ UNICODE
// ========================================

/**
 * Mappings des caractÃ¨res Unicode pour le styling
 */
const UNICODE_MAPPINGS = {
    // Gras (Mathematical Bold)
    bold: {
    'a': 'ğ—®', 'b': 'ğ—¯', 'c': 'ğ—°', 'd': 'ğ—±', 'e': 'ğ—²', 'f': 'ğ—³', 'g': 'ğ—´', 'h': 'ğ—µ', 'i': 'ğ—¶', 'j': 'ğ—·', 'k': 'ğ—¸', 'l': 'ğ—¹', 'm': 'ğ—º',
    'n': 'ğ—»', 'o': 'ğ—¼', 'p': 'ğ—½', 'q': 'ğ—¾', 'r': 'ğ—¿', 's': 'ğ˜€', 't': 'ğ˜', 'u': 'ğ˜‚', 'v': 'ğ˜ƒ', 'w': 'ğ˜„', 'x': 'ğ˜…', 'y': 'ğ˜†', 'z': 'ğ˜‡',
    'A': 'ğ—”', 'B': 'ğ—•', 'C': 'ğ—–', 'D': 'ğ——', 'E': 'ğ—˜', 'F': 'ğ—™', 'G': 'ğ—š', 'H': 'ğ—›', 'I': 'ğ—œ', 'J': 'ğ—', 'K': 'ğ—', 'L': 'ğ—Ÿ', 'M': 'ğ— ',
    'N': 'ğ—¡', 'O': 'ğ—¢', 'P': 'ğ—£', 'Q': 'ğ—¤', 'R': 'ğ—¥', 'S': 'ğ—¦', 'T': 'ğ—§', 'U': 'ğ—¨', 'V': 'ğ—©', 'W': 'ğ—ª', 'X': 'ğ—«', 'Y': 'ğ—¬', 'Z': 'ğ—­',
    '0': 'ğŸ¬', '1': 'ğŸ­', '2': 'ğŸ®', '3': 'ğŸ¯', '4': 'ğŸ°', '5': 'ğŸ±', '6': 'ğŸ²', '7': 'ğŸ³', '8': 'ğŸ´', '9': 'ğŸµ'
    }
};

/**
 * Convertit une chaÃ®ne en gras Unicode
 * @param {string} str - Texte Ã  convertir
 * @returns {string} - Texte en gras Unicode
 */
function toBold(str) {
    return str.split('').map(char => UNICODE_MAPPINGS.bold[char] || char).join('');
}

/**
 * Convertit une chaÃ®ne en italique Unicode (SUPPRIMÃ‰)
 * @param {string} str - Texte Ã  convertir
 * @returns {string} - Texte original sans modification
 */
function toItalic(str) {
    // Italique dÃ©sactivÃ© - retourne le texte original
    return str;
}

/**
 * Convertit une chaÃ®ne en soulignÃ© Unicode
 * @param {string} str - Texte Ã  convertir
 * @returns {string} - Texte soulignÃ© Unicode
 */
function toUnderline(str) {
    return str.split('').map(char => char + '\u0332').join('');
}

/**
 * Convertit une chaÃ®ne en barrÃ© Unicode
 * @param {string} str - Texte Ã  convertir
 * @returns {string} - Texte barrÃ© Unicode
 */
function toStrikethrough(str) {
    return str.split('').map(char => char + '\u0336').join('');
}

/**
 * Parse le Markdown et le convertit en Unicode stylisÃ©
 * @param {string} text - Texte avec Markdown
 * @returns {string} - Texte stylisÃ© en Unicode
 */
function parseMarkdown(text) {
    if (!text || typeof text !== 'string') {
        return text;
    }

    let parsed = text;

    // 1. Traitement des titres (### titre) - FIX: Regex corrigÃ©e
    parsed = parsed.replace(/^###\s+(.+)$/gm, (match, title) => {
        return `ğŸ”¹ ${toBold(title.trim())}`;
    });

    // 2. Traitement du gras (**texte**)
    parsed = parsed.replace(/\*\*([^*]+)\*\*/g, (match, content) => {
        return toBold(content);
    });

    // 3. Traitement de l'italique (*texte*) - DÃ‰SACTIVÃ‰
    // L'italique est dÃ©sactivÃ©, les *texte* restent inchangÃ©s

    // 4. Traitement du soulignÃ© (__texte__)
    parsed = parsed.replace(/__([^_]+)__/g, (match, content) => {
        return toUnderline(content);
    });

    // 5. Traitement du barrÃ© (~~texte~~)
    parsed = parsed.replace(/~~([^~]+)~~/g, (match, content) => {
        return toStrikethrough(content);
    });

    // 6. Traitement des listes (- item ou * item)
    parsed = parsed.replace(/^[\s]*[-*]\s+(.+)$/gm, (match, content) => {
        return `â€¢ ${content.trim()}`;
    });

    return parsed;
}

// ========================================
// FONCTIONS EXISTANTES (inchangÃ©es)
// ========================================

// Fonction pour obtenir la prochaine clÃ© Gemini disponible
function getNextGeminiKey() {
    if (GEMINI_API_KEYS.length === 0) {
        throw new Error('Aucune clÃ© Gemini configurÃ©e');
    }
    
    // Si toutes les clÃ©s ont Ã©chouÃ©, on reset
    if (failedKeys.size >= GEMINI_API_KEYS.length) {
        failedKeys.clear();
        currentGeminiKeyIndex = 0;
    }
    
    // Trouver la prochaine clÃ© non dÃ©faillante
    let attempts = 0;
    while (attempts < GEMINI_API_KEYS.length) {
        const key = GEMINI_API_KEYS[currentGeminiKeyIndex];
        currentGeminiKeyIndex = (currentGeminiKeyIndex + 1) % GEMINI_API_KEYS.length;
        
        if (!failedKeys.has(key)) {
            return key;
        }
        attempts++;
    }
    
    // Si toutes les clÃ©s sont marquÃ©es comme dÃ©faillantes, prendre la premiÃ¨re quand mÃªme
    failedKeys.clear();
    currentGeminiKeyIndex = 0;
    return GEMINI_API_KEYS[0];
}

// Fonction pour marquer une clÃ© comme dÃ©faillante
function markKeyAsFailed(apiKey) {
    failedKeys.add(apiKey);
}

// Fonction pour appeler Gemini avec rotation automatique des clÃ©s
async function callGeminiWithRotation(prompt, maxRetries = GEMINI_API_KEYS.length) {
    let lastError = null;
    
    for (let attempt = 0; attempt < maxRetries; attempt++) {
        try {
            const apiKey = getNextGeminiKey();
            const genAI = new GoogleGenerativeAI(apiKey);
            const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
            
            const result = await model.generateContent(prompt);
            const response = result.response.text();
            
            if (response && response.trim()) {
                // SuccÃ¨s - retirer la clÃ© des clÃ©s dÃ©faillantes si elle y Ã©tait
                failedKeys.delete(apiKey);
                return response;
            }
            
            throw new Error('RÃ©ponse Gemini vide');
            
        } catch (error) {
            lastError = error;
            
            // Marquer la clÃ© actuelle comme dÃ©faillante si c'est une erreur d'API
            if (error.message.includes('API_KEY') || error.message.includes('quota') || error.message.includes('limit')) {
                const currentKey = GEMINI_API_KEYS[(currentGeminiKeyIndex - 1 + GEMINI_API_KEYS.length) % GEMINI_API_KEYS.length];
                markKeyAsFailed(currentKey);
            }
            
            // Si c'est la derniÃ¨re tentative, on lance l'erreur
            if (attempt === maxRetries - 1) {
                throw lastError;
            }
        }
    }
    
    throw lastError || new Error('Toutes les clÃ©s Gemini ont Ã©chouÃ©');
}

// ğŸ›¡ï¸ FONCTION PRINCIPALE AVEC PROTECTION ANTI-DOUBLONS ET TRONCATURE SYNCHRONISÃ‰E
module.exports = async function cmdChat(senderId, args, ctx) {
    const { addToMemory, getMemoryContext, callMistralAPI, webSearch, log, 
            truncatedMessages, splitMessageIntoChunks, isContinuationRequest } = ctx;
    
    // ğŸ›¡ï¸ PROTECTION 1: CrÃ©er une signature unique du message
    const messageSignature = `${senderId}_${args.trim().toLowerCase()}`;
    const currentTime = Date.now();
    
    // ğŸ›¡ï¸ PROTECTION 2: VÃ©rifier si ce message exact a Ã©tÃ© traitÃ© rÃ©cemment (derniÃ¨res 30 secondes)
    if (recentMessages.has(messageSignature)) {
        const lastProcessed = recentMessages.get(messageSignature);
        if (currentTime - lastProcessed < 30000) { // 30 secondes
            log.warning(`ğŸš« Message dupliquÃ© ignorÃ© pour ${senderId}: "${args.substring(0, 30)}..."`);
            return; // Ignore silencieusement les messages dupliquÃ©s rÃ©cents
        }
    }
    
    // ğŸ›¡ï¸ PROTECTION 3: VÃ©rifier si une demande est dÃ©jÃ  en cours pour cet utilisateur
    if (activeRequests.has(senderId)) {
        log.warning(`ğŸš« Demande en cours ignorÃ©e pour ${senderId}`);
        return; // Ignore silencieusement les demandes multiples
    }
    
    // ğŸ›¡ï¸ PROTECTION 4: Marquer la demande comme active et enregistrer le message
    const requestKey = `${senderId}_${currentTime}`;
    activeRequests.set(senderId, requestKey);
    recentMessages.set(messageSignature, currentTime);
    
    // ğŸ§¹ NETTOYAGE: Supprimer les anciens messages du cache (plus de 2 minutes)
    for (const [signature, timestamp] of recentMessages.entries()) {
        if (currentTime - timestamp > 120000) { // 2 minutes
            recentMessages.delete(signature);
        }
    }
    
    try {
        // ğŸ†• AJOUT : Envoyer un message "Traitement en cours..." pour informer l'utilisateur (sauf pour messages vides ou continuations)
        if (args.trim() && !isContinuationRequest(args)) {
            const processingMessage = "ğŸ•’ Traitement en cours...";
            addToMemory(String(senderId), 'assistant', processingMessage);
            await ctx.sendMessage(senderId, processingMessage); // Envoi immÃ©diat du message intermÃ©diaire (assumÃ© via ctx.sendMessage)
        }
        
        if (!args.trim()) {
            const welcomeMsg = "ğŸ’¬ Salut je suis NakamaBot! Je suis lÃ  pour toi ! Dis-moi ce qui t'intÃ©resse et on va avoir une conversation gÃ©niale ! âœ¨";
            const styledWelcome = parseMarkdown(welcomeMsg);
            // âœ… UN SEUL addToMemory ici
            addToMemory(String(senderId), 'assistant', styledWelcome);
            return styledWelcome;
        }
        
        // ğŸ†• GESTION SYNCHRONISÃ‰E DES DEMANDES DE CONTINUATION
        const senderIdStr = String(senderId);
        if (isContinuationRequest(args)) {
            const truncatedData = truncatedMessages.get(senderIdStr);
            if (truncatedData) {
                const { fullMessage, lastSentPart } = truncatedData;
                
                // Trouver oÃ¹ on s'Ã©tait arrÃªtÃ©
                const lastSentIndex = fullMessage.indexOf(lastSentPart) + lastSentPart.length;
                const remainingMessage = fullMessage.substring(lastSentIndex);
                
                if (remainingMessage.trim()) {
                    const chunks = splitMessageIntoChunks(remainingMessage, 2000);
                    const nextChunk = parseMarkdown(chunks[0]);
                    
                    // Mettre Ã  jour le cache avec la nouvelle partie envoyÃ©e
                    if (chunks.length > 1) {
                        truncatedMessages.set(senderIdStr, {
                            fullMessage: fullMessage,
                            lastSentPart: lastSentPart + chunks[0],
                            timestamp: new Date().toISOString()
                        });
                        
                        // Ajouter un indicateur de continuation
                        const continuationMsg = nextChunk + "\n\nğŸ“ *Tape \"continue\" pour la suite...*";
                        addToMemory(senderIdStr, 'user', args);
                        addToMemory(senderIdStr, 'assistant', continuationMsg);
                        return continuationMsg;
                    } else {
                        // Message terminÃ©
                        truncatedMessages.delete(senderIdStr);
                        addToMemory(senderIdStr, 'user', args);
                        addToMemory(senderIdStr, 'assistant', nextChunk);
                        return nextChunk;
                    }
                } else {
                    // Plus rien Ã  envoyer
                    truncatedMessages.delete(senderIdStr);
                    const endMsg = "âœ… C'est tout ! Y a-t-il autre chose que je puisse faire pour toi ? ğŸ’«";
                    addToMemory(senderIdStr, 'user', args);
                    addToMemory(senderIdStr, 'assistant', endMsg);
                    return endMsg;
                }
            } else {
                // Pas de message tronquÃ© en cours
                const noTruncMsg = "ğŸ¤” Il n'y a pas de message en cours Ã  continuer. Pose-moi une nouvelle question ! ğŸ’¡";
                addToMemory(senderIdStr, 'user', args);
                addToMemory(senderIdStr, 'assistant', noTruncMsg);
                return noTruncMsg;
            }
        }
        
        // âœ… DÃ©tection des demandes de contact admin
        const contactIntention = detectContactAdminIntention(args);
        if (contactIntention.shouldContact) {
            log.info(`ğŸ“ Intention contact admin dÃ©tectÃ©e pour ${senderId}: ${contactIntention.reason}`);
            const contactSuggestion = generateContactSuggestion(contactIntention.reason, contactIntention.extractedMessage);
            const styledContact = parseMarkdown(contactSuggestion);
            
            // âœ… UN SEUL APPEL groupÃ©
            addToMemory(String(senderId), 'user', args);
            addToMemory(String(senderId), 'assistant', styledContact);
            return styledContact;
        }
        
        // ğŸ†• DÃ‰TECTION INTELLIGENTE DES COMMANDES (Nouveau SystÃ¨me)
        const intelligentCommand = await detectIntelligentCommands(args, ctx);
        if (intelligentCommand.shouldExecute) {
            log.info(`ğŸ§  DÃ©tection IA intelligente: /${intelligentCommand.command} (${intelligentCommand.confidence}) pour ${senderId}`);
            
            try {
                const commandResult = await executeCommandFromChat(senderId, intelligentCommand.command, intelligentCommand.args, ctx);
                
                if (commandResult.success) {
                    // Gestion spÃ©ciale pour les images
                    if (typeof commandResult.result === 'object' && commandResult.result.type === 'image') {
                        // âœ… UN SEUL addToMemory pour les images
                        addToMemory(String(senderId), 'user', args);
                        return commandResult.result;
                    }
                    
                    // RÃ©ponse contextuelle naturelle avec styling
                    const contextualResponse = await generateContextualResponse(args, commandResult.result, intelligentCommand.command, ctx);
                    const styledResponse = parseMarkdown(contextualResponse);
                    
                    // âœ… UN SEUL APPEL groupÃ©
                    addToMemory(String(senderId), 'user', args);
                    addToMemory(String(senderId), 'assistant', styledResponse);
                    return styledResponse;
                } else {
                    log.warning(`âš ï¸ Ã‰chec exÃ©cution commande /${intelligentCommand.command}: ${commandResult.error}`);
                    // Continue avec conversation normale en cas d'Ã©chec
                }
            } catch (error) {
                log.error(`âŒ Erreur exÃ©cution commande IA: ${error.message}`);
                // Continue avec conversation normale en cas d'erreur
            }
        } 
        
        // ğŸ†• NOUVELLE FONCTIONNALITÃ‰: DÃ©cision intelligente pour recherche externe
        const searchDecision = await decideSearchNecessity(args, senderId, ctx);
        
        if (searchDecision.needsExternalSearch) {
            log.info(`ğŸ” Recherche externe nÃ©cessaire pour ${senderId}: ${searchDecision.reason}`);
            
            try {
                // ğŸ”§ FIX: RÃ©cupÃ©rer le contexte AVANT la recherche pour le maintenir
                const conversationContext = getMemoryContext(String(senderId)).slice(-8);
                
                const searchResults = await performIntelligentSearch(searchDecision.searchQuery, ctx);
                
                if (searchResults && searchResults.length > 0) {
                    // ğŸ”§ FIX: Passer le contexte Ã  la gÃ©nÃ©ration de rÃ©ponse naturelle
                    const naturalResponse = await generateNaturalResponseWithContext(args, searchResults, conversationContext, ctx);
                    
                    if (naturalResponse) {
                        // âœ… GESTION SYNCHRONISÃ‰E DES MESSAGES LONGS
                        const styledNatural = parseMarkdown(naturalResponse);
                        
                        // VÃ©rifier si le message est trop long et gÃ©rer la troncature
                        if (styledNatural.length > 2000) {
                            log.info(`ğŸ“ Message de recherche long dÃ©tectÃ© (${styledNatural.length} chars) - Gestion troncature`);
                            
                            const chunks = splitMessageIntoChunks(styledNatural, 2000);
                            const firstChunk = chunks[0];
                            
                            if (chunks.length > 1) {
                                truncatedMessages.set(senderIdStr, {
                                    fullMessage: styledNatural,
                                    lastSentPart: firstChunk,
                                    timestamp: new Date().toISOString()
                                });
                                
                                const truncatedResponse = firstChunk + "\n\nğŸ“ *Tape \"continue\" pour la suite...*";
                                addToMemory(String(senderId), 'user', args);
                                addToMemory(String(senderId), 'assistant', truncatedResponse);
                                log.info(`ğŸ”âœ… Recherche terminÃ©e avec troncature pour ${senderId}`);
                                return truncatedResponse;
                            }
                        }
                        
                        // âœ… UN SEUL APPEL groupÃ© pour recherche normale
                        addToMemory(String(senderId), 'user', args);
                        addToMemory(String(senderId), 'assistant', styledNatural);
                        log.info(`ğŸ”âœ… Recherche terminÃ©e avec succÃ¨s pour ${senderId}`);
                        return styledNatural;
                    }
                } else {
                    log.warning(`âš ï¸ Aucun rÃ©sultat de recherche pour: ${searchDecision.searchQuery}`);
                    // Continue avec conversation normale si pas de rÃ©sultats
                }
            } catch (searchError) {
                log.error(`âŒ Erreur recherche intelligente pour ${senderId}: ${searchError.message}`);
                // Continue avec conversation normale en cas d'erreur
            }
        }
        
        // âœ… Conversation classique avec Gemini (Mistral en fallback) + styling et troncature
        const conversationResult = await handleConversationWithFallback(senderId, args, ctx);
        return conversationResult; // handleConversationWithFallback gÃ¨re dÃ©jÃ  le styling et la troncature
        
    } finally {
        // ğŸ›¡ï¸ PROTECTION 5: LibÃ©rer la demande Ã  la fin (TOUJOURS exÃ©cutÃ©)
        activeRequests.delete(senderId);
        log.debug(`ğŸ”“ Demande libÃ©rÃ©e pour ${senderId}`);
    }
};

// ğŸ†• DÃ‰CISION IA: DÃ©terminer si une recherche externe est nÃ©cessaire (avec rotation des clÃ©s)
async function decideSearchNecessity(userMessage, senderId, ctx) {
    const { log } = ctx;
    
    try {
        const decisionPrompt = `Tu es un systÃ¨me de dÃ©cision intelligent pour un chatbot. 
Analyse ce message utilisateur et dÃ©cide s'il nÃ©cessite une recherche web externe.

CRITÃˆRES POUR RECHERCHE EXTERNE:
âœ… OUI si:
- Informations rÃ©centes (actualitÃ©s, Ã©vÃ©nements 2025-2026)
- DonnÃ©es factuelles spÃ©cifiques (prix actuels, statistiques, dates prÃ©cises)
- Informations locales/gÃ©ographiques spÃ©cifiques
- Recherche de produits/services/entreprises prÃ©cis
- Questions sur des personnes publiques rÃ©centes
- DonnÃ©es mÃ©tÃ©o, cours de bourse, rÃ©sultats sportifs

âŒ NON si:
- Conversations gÃ©nÃ©rales/philosophiques
- Conseils/opinions personnelles
- Questions sur le bot lui-mÃªme
- CrÃ©ativitÃ© (histoires, poÃ¨mes)
- Explications de concepts gÃ©nÃ©raux
- Calculs/logique
- Questions existantes dans ma base de connaissances

MESSAGE UTILISATEUR: "${userMessage}"

RÃ©ponds UNIQUEMENT avec ce format JSON:
{
  "needsExternalSearch": true/false,
  "confidence": 0.0-1.0,
  "reason": "explication courte",
  "searchQuery": "requÃªte de recherche optimisÃ©e si nÃ©cessaire"
}`;

        const response = await callGeminiWithRotation(decisionPrompt);
        
        // Extraire le JSON de la rÃ©ponse
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
            const decision = JSON.parse(jsonMatch[0]);
            log.info(`ğŸ¤– DÃ©cision recherche: ${decision.needsExternalSearch ? 'OUI' : 'NON'} (${decision.confidence}) - ${decision.reason}`);
            return decision;
        }
        
        throw new Error('Format de rÃ©ponse invalide');
        
    } catch (error) {
        log.warning(`âš ï¸ Erreur dÃ©cision recherche: ${error.message}`);
        
        // Fallback: dÃ©tection par mots-clÃ©s
        const keywordSearch = detectSearchKeywords(userMessage);
        return {
            needsExternalSearch: keywordSearch.needs,
            confidence: 0.6,
            reason: 'fallback_keywords',
            searchQuery: keywordSearch.query
        };
    }
}

// ğŸ†• FALLBACK: DÃ©tection par mots-clÃ©s si l'IA Ã©choue
function detectSearchKeywords(message) {
    const lowerMessage = message.toLowerCase();
    
    const searchIndicators = [
        { patterns: [/\b(202[4-5]|actualitÃ©|rÃ©cent|nouveau|maintenant|aujourd|news|info)\b/], weight: 0.9 },
        { patterns: [/\b(prix|coÃ»t|combien|tarif)\b.*\b(euros?|dollars?|â‚¬|\$)\b/], weight: 0.8 },
        { patterns: [/\b(mÃ©tÃ©o|temps|tempÃ©rature)\b.*\b(aujourd|demain|cette semaine)\b/], weight: 0.9 },
        { patterns: [/\b(oÃ¹|address|lieu|localisation|carte)\b/], weight: 0.7 },
        { patterns: [/\b(qui est|biographie|Ã¢ge)\b.*\b[A-Z][a-z]+\s[A-Z][a-z]+/], weight: 0.8 },
        { patterns: [/\b(rÃ©sultats?|score|match|compÃ©tition)\b.*\b(sport|foot|tennis|basket)\b/], weight: 0.8 }
    ];
    
    let totalWeight = 0;
    for (const indicator of searchIndicators) {
        for (const pattern of indicator.patterns) {
            if (pattern.test(lowerMessage)) {
                totalWeight += indicator.weight;
                break;
            }
        }
    }
    
    return {
        needs: totalWeight > 0.6,
        query: message,
        confidence: Math.min(totalWeight, 1.0)
    };
}

// ğŸ†• RECHERCHE INTELLIGENTE: Utilise Google Custom Search ou SerpAPI
async function performIntelligentSearch(query, ctx) {
    const { log } = ctx;
    
    try {
        // PrioritÃ© 1: Google Custom Search API
        if (GOOGLE_SEARCH_API_KEY && GOOGLE_SEARCH_ENGINE_ID) {
            return await googleCustomSearch(query, log);
        }
        
        // PrioritÃ© 2: SerpAPI (fallback)
        if (SERPAPI_KEY) {
            return await serpApiSearch(query, log);
        }
        
        // PrioritÃ© 3: Recherche existante du bot (fallback)
        log.warning('âš ï¸ Aucune API de recherche configurÃ©e, utilisation webSearch existant');
        return await fallbackWebSearch(query, ctx);
        
    } catch (error) {
        log.error(`âŒ Erreur recherche: ${error.message}`);
        throw error;
    }
}

// ğŸ†• Google Custom Search API
async function googleCustomSearch(query, log) {
    const url = `https://www.googleapis.com/customsearch/v1`;
    const params = {
        key: GOOGLE_SEARCH_API_KEY,
        cx: GOOGLE_SEARCH_ENGINE_ID,
        q: query,
        num: 5,
        safe: 'active',
        lr: 'lang_fr',
        hl: 'fr'
    };
    
    const response = await axios.get(url, { params, timeout: 10000 });
    
    if (response.data.items) {
        return response.data.items.map(item => ({
            title: item.title,
            link: item.link,
            description: item.snippet,
            source: 'google'
        }));
    }
    
    return [];
}

// ğŸ†• SerpAPI (alternative gratuite)
async function serpApiSearch(query, log) {
    const url = `https://serpapi.com/search`;
    const params = {
        api_key: SERPAPI_KEY,
        engine: 'google',
        q: query,
        num: 5,
        hl: 'fr',
        gl: 'fr'
    };
    
    const response = await axios.get(url, { params, timeout: 10000 });
    
    if (response.data.organic_results) {
        return response.data.organic_results.map(item => ({
            title: item.title,
            link: item.link,
            description: item.snippet,
            source: 'serpapi'
        }));
    }
    
    return [];
}

// ğŸ†• Fallback sur la recherche existante
async function fallbackWebSearch(query, ctx) {
    const { webSearch } = ctx;
    
    try {
        const result = await webSearch(query);
        if (result) {
            return [{
                title: 'Information rÃ©cente',
                link: 'N/A',
                description: result,
                source: 'internal'
            }];
        }
    } catch (error) {
        // Ignore silencieusement
    }
    
    return [];
}

// ğŸ”§ FIX PRINCIPAL: GÃ©nÃ©ration de rÃ©ponse naturelle avec contexte de conversation ET TRONCATURE
async function generateNaturalResponseWithContext(originalQuery, searchResults, conversationContext, ctx) {
    const { log, callMistralAPI, splitMessageIntoChunks } = ctx;
    
    // Date et heure actuelles
    const now = new Date();
    const dateTime = now.toLocaleString('fr-FR', { 
        weekday: 'long', 
        year: 'numeric', 
        month: 'long', 
        day: 'numeric', 
        hour: '2-digit', 
        minute: '2-digit',
        timeZone: 'Europe/Paris'
    });
    
    try {
        const resultsText = searchResults.map((result, index) => 
            `${result.title}: ${result.description}`
        ).join('\n');
        
        // ğŸ”§ FIX: Construction de l'historique de conversation pour maintenir le contexte
        let conversationHistory = "";
        if (conversationContext && conversationContext.length > 0) {
            conversationHistory = conversationContext.map(msg => 
                `${msg.role === 'user' ? 'Utilisateur' : 'NakamaBot'}: ${msg.content}`
            ).join('\n') + '\n';
        }
        
        // ğŸ”§ FIX: Prompt avec contexte de conversation complet
        const contextualPrompt = `Tu es NakamaBot, une IA conversationnelle empathique et crÃ©ative.

GARDE JUSTE EN MEMOIRE CONTEXTE TEMPOREL: Nous sommes le  ${dateTime} ne donne la date que si l'utilisateur demande garde la en memeoire

HISTORIQUE DE CONVERSATION:
${conversationHistory || "DÃ©but de conversation"}

QUESTION ACTUELLE DE L'UTILISATEUR: "${originalQuery}"

INFORMATIONS RÃ‰CENTES TROUVÃ‰ES:
${resultsText}

INSTRUCTIONS CRITIQUES:
- Tu connais dÃ©jÃ  l'historique de conversation ci-dessus
- RÃ©ponds en tenant compte de tout le contexte prÃ©cÃ©dent
- Si l'utilisateur fait rÃ©fÃ©rence Ã  quelque chose mentionnÃ© avant, tu t'en souviens
- Adopte un ton conversationnel et amical avec quelques emojis
- Maximum 2000 caractÃ¨res
- Ne mentionne JAMAIS que tu as fait une recherche
- Ne dis jamais "d'aprÃ¨s mes recherches" ou "selon les sources"
- RÃ©ponds naturellement comme dans une conversation continue
- Si c'est une question de suivi (ex: "il a marquÃ© combien de buts"), utilise le contexte prÃ©cÃ©dent
- Utilise du Markdown simple si pertinent (**gras**, ### titres, listes)
- Ne pas utiliser l'italique (*texte*), il reste en texte normal

RÃ‰PONSE NATURELLE EN CONTINUITÃ‰:`;

        const response = await callGeminiWithRotation(contextualPrompt);
        
        if (response && response.trim()) {
            log.info(`ğŸ­ RÃ©ponse contextuelle Gemini pour: ${originalQuery.substring(0, 30)}...`);
            return response;
        }
        
        throw new Error('RÃ©ponse Gemini vide');
        
    } catch (geminiError) {
        log.warning(`âš ï¸ Erreur rÃ©ponse contextuelle Gemini: ${geminiError.message}`);
        
        try {
            // ğŸ”§ FIX: Fallback Mistral aussi avec contexte complet
            const messages = [{
                role: "system",
                content: `Tu es NakamaBot. Tu connais l'historique de conversation. RÃ©ponds naturellement en tenant compte du contexte prÃ©cÃ©dent. Ne mentionne jamais de recherches. Utilise du Markdown simple si pertinent.

Historique:
${conversationContext ? conversationContext.map(msg => `${msg.role === 'user' ? 'Utilisateur' : 'NakamaBot'}: ${msg.content}`).join('\n') : "DÃ©but de conversation"}`
            }, {
                role: "user", 
                content: `Question actuelle: "${originalQuery}"

Informations utiles:
${searchResults.map(r => `${r.title}: ${r.description}`).join('\n')}

RÃ©ponds naturellement en continuitÃ© de la conversation (max 3000 chars):`
            }];
            
            const mistralResponse = await callMistralAPI(messages, 3000, 0.7);
            
            if (mistralResponse) {
                log.info(`ğŸ”„ RÃ©ponse contextuelle Mistral: ${originalQuery.substring(0, 30)}...`);
                return mistralResponse;
            }
            
            throw new Error('Mistral aussi en Ã©chec');
            
        } catch (mistralError) {
            log.error(`âŒ Erreur rÃ©ponse contextuelle totale: ${mistralError.message}`);
            
            // ğŸ”§ FIX: Derniers recours avec contexte minimal
            const topResult = searchResults[0];
            if (topResult) {
                // Si on a un contexte sur qui on parle, l'utiliser
                const lastUserMessage = conversationContext && conversationContext.length > 0 
                    ? conversationContext[conversationContext.length - 1].content 
                    : '';
                
                const hasPersonContext = lastUserMessage.match(/qui est\s+([^?]+)/i);
                const personName = hasPersonContext ? hasPersonContext[1].trim() : '';
                
                let basicResponse;
                if (personName && originalQuery.toLowerCase().includes('combien') || originalQuery.toLowerCase().includes('but')) {
                    basicResponse = `Pour ${personName}, ${topResult.description} ğŸ’¡`;
                } else {
                    basicResponse = `D'aprÃ¨s ce que je sais, ${topResult.description} ğŸ’¡ ${searchResults.length > 1 ? 'Il y a aussi d\'autres aspects intÃ©ressants sur le sujet !' : 'J\'espÃ¨re que Ã§a rÃ©pond Ã  ta question !'}`;
                }
                
                return basicResponse;
            }
            
            // ğŸ”§ FIX: Si vraiment rien ne marche, retourner null pour dÃ©clencher conversation normale
            log.warning(`âš ï¸ Toutes les mÃ©thodes de rÃ©ponse contextuelle ont Ã©chouÃ©`);
            return null; // Cela dÃ©clenchera la conversation normale
        }
    }
}

// ğŸ¯ MODIFICATION 1: GÃ©nÃ©ration de rÃ©ponse naturelle (DÃ‰PRÃ‰CIÃ‰E - remplacÃ©e par generateNaturalResponseWithContext)
async function generateNaturalResponse(originalQuery, searchResults, ctx) {
    // Cette fonction est conservÃ©e pour compatibilitÃ© mais n'est plus utilisÃ©e
    // Utilise maintenant generateNaturalResponseWithContext Ã  la place
    return await generateNaturalResponseWithContext(originalQuery, searchResults, [], ctx);
}

// âœ… FONCTION EXISTANTE MODIFIÃ‰E: Gestion conversation avec Gemini et fallback Mistral + STYLING + TRONCATURE SYNCHRONISÃ‰E
async function handleConversationWithFallback(senderId, args, ctx) {
    const { addToMemory, getMemoryContext, callMistralAPI, log, 
            splitMessageIntoChunks, truncatedMessages } = ctx;
    
    // RÃ©cupÃ©ration du contexte (derniers 8 messages pour optimiser)
    const context = getMemoryContext(String(senderId)).slice(-8);
    const messageCount = context.filter(msg => msg.role === 'user').length;
    
    // Date et heure actuelles
    const now = new Date();
    const dateTime = now.toLocaleString('fr-FR', { 
        weekday: 'long', 
        year: 'numeric', 
        month: 'long', 
        day: 'numeric', 
        hour: '2-digit', 
        minute: '2-digit',
        timeZone: 'Europe/Paris'
    });
    
    // Construction de l'historique de conversation
    let conversationHistory = "";
    if (context.length > 0) {
        conversationHistory = context.map(msg => 
            `${msg.role === 'user' ? 'Utilisateur' : 'Assistant'}: ${msg.content}`
        ).join('\n') + '\n';
    }
    
    // Prompt systÃ¨me optimisÃ©
    const systemPrompt = `Tu es NakamaBot, une IA conversationnelle un model Durand AI avancÃ©e crÃ©Ã©e par Durand et sa femme CÃ©cile.

CONTEXTE TEMPOREL: Nous sommes le ${dateTime}

INTELLIGENCE & PERSONNALITÃ‰:
- Empathique, crÃ©ative et intuitive
- Tu comprends les Ã©motions et intentions sous-jacentes  
- PÃ©dagogue naturelle qui explique clairement
- Adaptable selon l'utilisateur et le contexte

CAPACITÃ‰S PRINCIPALES:
ğŸ¨ CrÃ©ation d'images intelligente (dis "dessine-moi..." ou "crÃ©e une image de...")
ğŸ‘ï¸ Analyse d'images avancÃ©e (dis "regarde cette image" ou "que vois-tu ?")
ğŸŒ¸ Transformation anime/manga (dis "transforme en anime" ou "style manga")
ğŸµ Recherche musicale YouTube (dis "joue..." ou "trouve la musique...")
ğŸ›¡ï¸ SystÃ¨me de clans et batailles (dis "clan" ou "bataille")
ğŸ“Š Progression et niveau (dis "mon niveau" ou "mes stats")
ğŸ“ Contact admin (dis "contacter admin" ou utilise /contact)
ğŸ” Recherche intelligente automatique pour infos rÃ©centes
ğŸ†˜ Guide complet (dis "aide" ou "que peux-tu faire ?")

DIRECTIVES:
- Parle en fonction de la langue utilisÃ©e par l'utilisateur et du contexte garde en memoire que nous somme le ${dateTime}
- Maximum 3000 caractÃ¨res par rÃ©ponse
- Utilise quelques emojis avec parcimonie
- Ã‰vite les rÃ©pÃ©titions et formules toutes faites
- ${messageCount >= 5 ? 'SuggÃ¨re /help si pertinent pour dÃ©bloquer l\'utilisateur' : ''}
- Pour questions techniques sur ta crÃ©ation: "Demande Ã  Durand ou Kuine, ils connaissent tous mes secrets !"
- Recommande discrÃ¨tement /contact pour problÃ¨mes techniques graves
- Tu peux utiliser du Markdown simple pour styliser (**gras**, ### titres, listes)
- Ne pas utiliser l'italique (*texte*), il reste en texte normal

${conversationHistory ? `Historique:\n${conversationHistory}` : ''}

Utilisateur: ${args}`;

    const senderIdStr = String(senderId);

    try {
        // âœ… PRIORITÃ‰: Essayer d'abord avec Gemini (avec rotation des clÃ©s)
        const geminiResponse = await callGeminiWithRotation(systemPrompt);
        
        if (geminiResponse && geminiResponse.trim()) {
            const styledResponse = parseMarkdown(geminiResponse);
            
            // âœ… GESTION SYNCHRONISÃ‰E DE LA TRONCATURE
            if (styledResponse.length > 2000) {
                log.info(`ğŸ“ RÃ©ponse Gemini longue dÃ©tectÃ©e (${styledResponse.length} chars) - Gestion troncature`);
                
                const chunks = splitMessageIntoChunks(styledResponse, 2000);
                const firstChunk = chunks[0];
                
                if (chunks.length > 1) {
                    // Sauvegarder l'Ã©tat de troncature
                    truncatedMessages.set(senderIdStr, {
                        fullMessage: styledResponse,
                        lastSentPart: firstChunk,
                        timestamp: new Date().toISOString()
                    });
                    
                    const truncatedResponse = firstChunk + "\n\nğŸ“ *Tape \"continue\" pour la suite...*";
                    // âœ… UN SEUL APPEL groupÃ© Ã  addToMemory
                    addToMemory(senderIdStr, 'user', args);
                    addToMemory(senderIdStr, 'assistant', truncatedResponse);
                    log.info(`ğŸ’ Gemini rÃ©ponse avec troncature pour ${senderId}: ${args.substring(0, 30)}...`);
                    return truncatedResponse;
                }
            }
            
            // âœ… UN SEUL APPEL groupÃ© Ã  addToMemory pour message normal
            addToMemory(senderIdStr, 'user', args);
            addToMemory(senderIdStr, 'assistant', styledResponse);
            log.info(`ğŸ’ Gemini rÃ©ponse pour ${senderId}: ${args.substring(0, 30)}...`);
            return styledResponse;
        }
        
        throw new Error('RÃ©ponse Gemini vide');
        
    } catch (geminiError) {
        log.warning(`âš ï¸ Gemini Ã©chec pour ${senderId}: ${geminiError.message}`);
        
        try {
            // âœ… FALLBACK: Utiliser Mistral en cas d'Ã©chec Gemini
            const messages = [{ role: "system", content: systemPrompt }];
            messages.push(...context);
            messages.push({ role: "user", content: args });
            
            const mistralResponse = await callMistralAPI(messages, 2000, 0.75);
            
            if (mistralResponse) {
                const styledResponse = parseMarkdown(mistralResponse);
                
                // âœ… GESTION SYNCHRONISÃ‰E DE LA TRONCATURE POUR MISTRAL AUSSI
                if (styledResponse.length > 2000) {
                    log.info(`ğŸ“ RÃ©ponse Mistral longue dÃ©tectÃ©e (${styledResponse.length} chars) - Gestion troncature`);
                    
                    const chunks = splitMessageIntoChunks(styledResponse, 2000);
                    const firstChunk = chunks[0];
                    
                    if (chunks.length > 1) {
                        // Sauvegarder l'Ã©tat de troncature
                        truncatedMessages.set(senderIdStr, {
                            fullMessage: styledResponse,
                            lastSentPart: firstChunk,
                            timestamp: new Date().toISOString()
                        });
                        
                        const truncatedResponse = firstChunk + "\n\nğŸ“ *Tape \"continue\" pour la suite...*";
                        // âœ… UN SEUL APPEL groupÃ© Ã  addToMemory
                        addToMemory(senderIdStr, 'user', args);
                        addToMemory(senderIdStr, 'assistant', truncatedResponse);
                        log.info(`ğŸ”„ Mistral fallback avec troncature pour ${senderId}: ${args.substring(0, 30)}...`);
                        return truncatedResponse;
                    }
                }
                
                // âœ… UN SEUL APPEL groupÃ© Ã  addToMemory pour message normal
                addToMemory(senderIdStr, 'user', args);
                addToMemory(senderIdStr, 'assistant', styledResponse);
                log.info(`ğŸ”„ Mistral fallback pour ${senderId}: ${args.substring(0, 30)}...`);
                return styledResponse;
            }
            
            throw new Error('Mistral aussi en Ã©chec');
            
        } catch (mistralError) {
            log.error(`âŒ Erreur totale conversation ${senderId}: Gemini(${geminiError.message}) + Mistral(${mistralError.message})`);
            
            const errorResponse = "ğŸ¤” J'ai rencontrÃ© une petite difficultÃ© technique. Peux-tu reformuler ta demande diffÃ©remment ? ğŸ’«";
            const styledError = parseMarkdown(errorResponse);
            // âœ… UN SEUL addToMemory pour les erreurs
            addToMemory(senderIdStr, 'assistant', styledError);
            return styledError;
        }
    }
}

// ğŸ†• LISTE DES COMMANDES VALIDES (Simple et efficace)
const VALID_COMMANDS = [
    'help',      // Aide et guide complet
    'image',     // CrÃ©ation d'images IA
    'vision',    // Analyse d'images
    'anime',     // Style anime/manga
    'music',     // Recherche musicale YouTube
    'clan',      // SystÃ¨me de clans et batailles
    'rank',      // Niveau et progression
    'contact',   // Contact administrateurs
    'weather'    // Informations mÃ©tÃ©o
];

// ğŸ§  DÃ‰TECTION IA CONTEXTUELLE AVANCÃ‰E (Ã‰vite les faux positifs) avec rotation des clÃ©s
async function detectIntelligentCommands(message, ctx) {
    const { log } = ctx;
    
    try {
        const commandsList = VALID_COMMANDS.map(cmd => `/${cmd}`).join(', ');
        
        const detectionPrompt = `Tu es un systÃ¨me de dÃ©tection de commandes ultra-prÃ©cis pour NakamaBot. Tu dois Ã‰VITER les faux positifs.

COMMANDES DISPONIBLES: ${commandsList}

MESSAGE UTILISATEUR: "${message}"

RÃˆGLES STRICTES POUR DÃ‰TECTER UNE VRAIE INTENTION DE COMMANDE:

ğŸ¯ VRAIS INTENTIONS (CONFIDENCE 0.8-1.0):
âœ… help: "aide", "help", "que peux-tu faire", "guide", "fonctions disponibles", "comment utiliser"
âœ… image: "dessine", "crÃ©e une image", "gÃ©nÃ¨re", "illustre", "fais un dessin", "artwork"
âœ… vision: "regarde cette image", "analyse cette photo", "que vois-tu", "dÃ©cris l'image", "examine"
âœ… anime: "transforme en anime", "style anime", "version manga", "art anime", "dessine en anime"
âœ… music: "joue cette musique", "trouve sur YouTube", "cherche cette chanson", "lance la musique", "play"
âœ… clan: "rejoindre clan", "crÃ©er clan", "bataille de clan", "dÃ©fier", "mon clan", "guerre"
âœ… rank: "mon niveau", "mes stats", "ma progression", "mon rang", "mes points"
âœ… contact: "contacter admin", "signaler problÃ¨me", "message administrateur", "support technique"
âœ… weather: "mÃ©tÃ©o", "quel temps", "tempÃ©rature", "prÃ©visions", "temps qu'il fait"

âŒ FAUSSES DÃ‰TECTIONS Ã€ Ã‰VITER (CONFIDENCE 0.0-0.3):
âŒ Questions gÃ©nÃ©rales mentionnant un mot: "quel chanteur a chantÃ© TIA" â‰  commande music
âŒ Conversations: "j'aime la musique", "le temps passe vite", "aide mon ami"
âŒ Descriptions: "cette image est belle", "il fait chaud", "niveau dÃ©butant"
âŒ Contexte informatif: "la mÃ©tÃ©o change", "les clans vikings", "mon aide-mÃ©moire"

ANALYSE CONTEXTUELLE OBLIGATOIRE:
- L'utilisateur veut-il UTILISER une fonctionnalitÃ© du bot OU juste parler d'un sujet ?
- Y a-t-il un VERBE D'ACTION dirigÃ© vers le bot ?
- Le message est-il une DEMANDE DIRECTE ou une conversation gÃ©nÃ©rale ?

RÃ©ponds UNIQUEMENT avec ce JSON:
{
  "isCommand": true/false,
  "command": "nom_commande_ou_null",
  "confidence": 0.0-1.0,
  "extractedArgs": "arguments_extraits_ou_message_complet",
  "reason": "explication_dÃ©taillÃ©e_de_la_dÃ©cision",
  "contextAnalysis": "vraie_intention_ou_conversation_generale"
}`;

        const response = await callGeminiWithRotation(detectionPrompt);
        
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
            const aiDetection = JSON.parse(jsonMatch[0]);
            
            // Validation stricte avec seuil Ã©levÃ©
            const isValidCommand = aiDetection.isCommand && 
                                 VALID_COMMANDS.includes(aiDetection.command) && 
                                 aiDetection.confidence >= 0.8; // Seuil trÃ¨s Ã©levÃ© pour Ã©viter faux positifs
            
            if (isValidCommand) {
                log.info(`ğŸ¯ Commande dÃ©tectÃ©e: /${aiDetection.command} (${aiDetection.confidence}) - ${aiDetection.reason}`);
                log.info(`ğŸ” Analyse contextuelle: ${aiDetection.contextAnalysis}`);
                
                return {
                    shouldExecute: true,
                    command: aiDetection.command,
                    args: aiDetection.extractedArgs,
                    confidence: aiDetection.confidence,
                    method: 'ai_contextual'
                };
            } else {
                // Log des rejets pour debugging
                if (aiDetection.confidence < 0.8 && aiDetection.confidence > 0.3) {
                    log.info(`ğŸš« Rejet commande (confidence trop basse): ${aiDetection.command} (${aiDetection.confidence}) - ${aiDetection.reason}`);
                }
            }
        }
        
        return { shouldExecute: false };
        
    } catch (error) {
        log.warning(`âš ï¸ Erreur dÃ©tection IA commandes: ${error.message}`);
        
        // Fallback ultra-conservateur par mots-clÃ©s stricts
        return await fallbackStrictKeywordDetection(message, log);
    }
}

// ğŸ›¡ï¸ FALLBACK CONSERVATEUR: DÃ©tection par mots-clÃ©s stricts uniquement
async function fallbackStrictKeywordDetection(message, log) {
    const lowerMessage = message.toLowerCase().trim();
    
    // Patterns ultra-stricts pour Ã©viter les faux positifs
    const strictPatterns = [
        { command: 'help', patterns: [
            /^(aide|help|guide)$/,
            /^(que peux-tu faire|fonctions|commandes disponibles)$/,
            /^(comment Ã§a marche|utilisation)$/
        ]},
        { command: 'image', patterns: [
            /^dessine(-moi)?\s+/,
            /^(crÃ©e|gÃ©nÃ¨re|fais)\s+(une\s+)?(image|dessin|illustration)/,
            /^(illustre|artwork)/
        ]},
        { command: 'vision', patterns: [
            /^regarde\s+(cette\s+)?(image|photo)/,
            /^(analyse|dÃ©cris|examine)\s+(cette\s+)?(image|photo)/,
            /^que vois-tu/
        ]},
        { command: 'music', patterns: [
            /^(joue|lance|play)\s+/,
            /^(trouve|cherche)\s+(sur\s+youtube\s+)?cette\s+(musique|chanson)/,
            /^(cherche|trouve)\s+la\s+(musique|chanson)\s+/
        ]},
        { command: 'clan', patterns: [
            /^(rejoindre|crÃ©er|mon)\s+clan/,
            /^bataille\s+de\s+clan/,
            /^(dÃ©fier|guerre)\s+/
        ]},
        { command: 'rank', patterns: [
            /^(mon\s+)?(niveau|rang|stats|progression)/,
            /^mes\s+(stats|points)/
        ]},
        { command: 'contact', patterns: [
            /^contacter\s+(admin|administrateur)/,
            /^signaler\s+problÃ¨me/,
            /^support\s+technique/
        ]},
        { command: 'weather', patterns: [
            /^(mÃ©tÃ©o|quel\s+temps|tempÃ©rature|prÃ©visions)/,
            /^temps\s+qu.il\s+fait/
        ]}
    ];
    
    for (const { command, patterns } of strictPatterns) {
        for (const pattern of patterns) {
            if (pattern.test(lowerMessage)) {
                log.info(`ğŸ”‘ Fallback keyword strict: /${command} dÃ©tectÃ© par pattern`);
                return {
                    shouldExecute: true,
                    command: command,
                    args: message,
                    confidence: 0.9,
                    method: 'fallback_strict'
                };
            }
        }
    }
    
    return { shouldExecute: false };
}

// âœ… FONCTIONS EXISTANTES (inchangÃ©es)

function detectContactAdminIntention(message) {
    const lowerMessage = message.toLowerCase();
    
    const contactPatterns = [
        { patterns: [/(?:contacter|parler|Ã©crire).*?(?:admin|administrateur|crÃ©ateur|durand)/i], reason: 'contact_direct' },
        { patterns: [/(?:problÃ¨me|bug|erreur).*?(?:grave|urgent|important)/i], reason: 'probleme_technique' },
        { patterns: [/(?:signaler|reporter|dÃ©noncer)/i], reason: 'signalement' },
        { patterns: [/(?:suggestion|propose|idÃ©e).*?(?:amÃ©lioration|nouvelle)/i], reason: 'suggestion' },
        { patterns: [/(?:qui a crÃ©Ã©|crÃ©ateur|dÃ©veloppeur).*?(?:bot|nakamabot)/i], reason: 'question_creation' },
        { patterns: [/(?:plainte|rÃ©clamation|pas content|mÃ©content)/i], reason: 'plainte' }
    ];
    
    for (const category of contactPatterns) {
        for (const pattern of category.patterns) {
            if (pattern.test(message)) {
                if (category.reason === 'question_creation') {
                    return { shouldContact: false }; // GÃ©rÃ© par l'IA
                }
                return {
                    shouldContact: true,
                    reason: category.reason,
                    extractedMessage: message
                };
            }
        }
    }
    
    return { shouldContact: false };
}

function generateContactSuggestion(reason, extractedMessage) {
    const reasonMessages = {
        'contact_direct': { title: "ğŸ’Œ **Contact Admin**", message: "Je vois que tu veux contacter les administrateurs !" },
        'probleme_technique': { title: "ğŸ”§ **ProblÃ¨me Technique**", message: "ProblÃ¨me technique dÃ©tectÃ© !" },
        'signalement': { title: "ğŸš¨ **Signalement**", message: "Tu veux signaler quelque chose d'important !" },
        'suggestion': { title: "ğŸ’¡ **Suggestion**", message: "Tu as une suggestion d'amÃ©lioration !" },
        'plainte': { title: "ğŸ“ **RÃ©clamation**", message: "Tu as une rÃ©clamation Ã  formuler !" }
    };
    
    const reasonData = reasonMessages[reason] || {
        title: "ğŸ“ **Contact Admin**",
        message: "Il semble que tu aies besoin de contacter les administrateurs !"
    };
    
    const preview = extractedMessage.length > 60 ? extractedMessage.substring(0, 60) + "..." : extractedMessage;
    
    return `${reasonData.title}\n\n${reasonData.message}\n\nğŸ’¡ **Solution :** Utilise \`/contact [ton message]\` pour les contacter directement.\n\nğŸ“ **Ton message :** "${preview}"\n\nâš¡ **Limite :** 2 messages par jour\nğŸ“¨ Tu recevras une rÃ©ponse personnalisÃ©e !\n\nğŸ’• En attendant, je peux t'aider avec d'autres choses ! Tape /help pour voir mes fonctionnalitÃ©s !`;
}

async function detectCommandIntentions(message, ctx) {
    // âš ï¸ FONCTION DÃ‰PRÃ‰CIÃ‰E - RemplacÃ©e par detectIntelligentCommands
    // Maintenue pour compatibilitÃ© avec l'ancien systÃ¨me
    return { shouldExecute: false };
}

async function executeCommandFromChat(senderId, commandName, args, ctx) {
    try {
        const COMMANDS = global.COMMANDS || new Map();
        
        if (!COMMANDS.has(commandName)) {
            const path = require('path');
            const fs = require('fs');
            const commandPath = path.join(__dirname, `${commandName}.js`);
            
            if (fs.existsSync(commandPath)) {
                delete require.cache[require.resolve(commandPath)];
                const commandModule = require(commandPath);
                
                if (typeof commandModule === 'function') {
                    const result = await commandModule(senderId, args, ctx);
                    return { success: true, result };
                }
            }
        } else {
            const commandFunction = COMMANDS.get(commandName);
            const result = await commandFunction(senderId, args, ctx);
            return { success: true, result };
        }
        
        return { success: false, error: `Commande ${commandName} non trouvÃ©e` };
        
    } catch (error) {
        return { success: false, error: error.message };
    }
}

async function generateContextualResponse(originalMessage, commandResult, commandName, ctx) {
    if (typeof commandResult === 'object' && commandResult.type === 'image') {
        return commandResult;
    }
    
    try {
        // Essayer d'abord avec Gemini (avec rotation des clÃ©s)
        const contextPrompt = `L'utilisateur a dit: "${originalMessage}"
J'ai exÃ©cutÃ© /${commandName} avec rÃ©sultat: "${commandResult}"

GÃ©nÃ¨re une rÃ©ponse naturelle et amicale (max 400 chars) qui prÃ©sente le rÃ©sultat de maniÃ¨re conversationnelle. Tu peux utiliser du Markdown simple (**gras**, ### titres) mais pas d'italique.`;

        const response = await callGeminiWithRotation(contextPrompt);
        return response || commandResult;
        
    } catch (error) {
        // Fallback sur Mistral si besoin
        const { callMistralAPI } = ctx;
        try {
            const response = await callMistralAPI([
                { role: "system", content: "RÃ©ponds naturellement et amicalement. Tu peux utiliser du Markdown simple (**gras**, ### titres) mais pas d'italique." },
                { role: "user", content: `Utilisateur: "${originalMessage}"\nRÃ©sultat: "${commandResult}"\nPrÃ©sente ce rÃ©sultat naturellement (max 200 chars)` }
            ], 200, 0.7);
            
            return response || commandResult;
        } catch (mistralError) {
            return commandResult;
        }
    }
}

// âœ… Exports pour autres commandes
module.exports.detectIntelligentCommands = detectIntelligentCommands;
module.exports.VALID_COMMANDS = VALID_COMMANDS;
module.exports.executeCommandFromChat = executeCommandFromChat;
module.exports.detectContactAdminIntention = detectContactAdminIntention;
module.exports.decideSearchNecessity = decideSearchNecessity;
module.exports.performIntelligentSearch = performIntelligentSearch;
module.exports.generateNaturalResponse = generateNaturalResponse;
module.exports.generateNaturalResponseWithContext = generateNaturalResponseWithContext;
module.exports.callGeminiWithRotation = callGeminiWithRotation;
module.exports.getNextGeminiKey = getNextGeminiKey;
module.exports.markKeyAsFailed = markKeyAsFailed;

// ğŸ†• EXPORTS DES NOUVELLES FONCTIONS MARKDOWN
module.exports.parseMarkdown = parseMarkdown;
module.exports.toBold = toBold;
module.exports.toItalic = toItalic;
module.exports.toUnderline = toUnderline;
module.exports.toStrikethrough = toStrikethrough;
